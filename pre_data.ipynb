{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"D:\\thesis\\thesis\\rllib\")\n",
    "import os\n",
    "import rllib as rl\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "dataset_train = \"./ML/output/random2/symptoms/csv/symptoms.csv\"\n",
    "dataset_test = \"./data_preprossing/output/test_cleaned.csv\"\n",
    "symptom_map_file = \"./data/basic/symptoms_db.json\"\n",
    "condition_map_file = \"./data/basic/conditions_db.json\"\n",
    "group_file = \"./data/basic/conditions_group.json\"\n",
    "test = \"./data_preprossing/output/data/total_1k.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Acute pancreatitis': 2, 'Acute pyelonefritis': 7, 'Appendicitis': 2, 'Asthma': 1, 'Atrophic gastritis': 2, 'Bacterial meningitis': 4, 'Bladder cancer': 9, 'Breast cancer  female': 9, 'COPD': 1, 'Carpal tunnel syndrome': 5, 'Cauda equina': 5, 'Colon cancer': 9, 'Covid-19': 1, 'Female cystitis': 7, 'Functional constipation': 2, 'Genital herpes  female': 8, 'Genital herpes  male': 8, 'Giardiasis': 2, 'Gonorrhea, feminine': 8, 'Gout': 3, 'Hernia Nuclei Pulposi': 5, 'IBS (Constipation)': 2, 'Iron deficiency anaemia': 10, 'Lower urinary tract infection': 7, 'Lumbago': 5, 'Lumbar spinal stenosis': 5, 'Lung cancer': 9, 'Mastoiditis': 6, 'Migraine': 4, 'Norovirus gastroenteritis': 2, 'Oesophageal carcinoma': 9, 'Osteoarthritis': 3, 'Otitis externa': 6, 'Otitis media acuta': 6, 'Ovarian cancer': 9, 'Pneumococcal pneumonia': 1, 'Pneumothorax': 1, 'Pulmonary edema  old': 1, 'Pulmonary edema  oldest': 1, 'Pulmonary edema  young': 1, 'Rheumatoid arthritis  feminine': 3, 'Rheumatoid arthritis  masculine': 3, 'Salmonella infection': 2, 'Seasonal Influenza': 1, 'Subarachnoidal bleeding': 4, 'Tension type headache': 4, 'Testicular cancer': 9, 'Upper urinary tract infection': 7, 'Viral meningitis  enterovirus': 4, 'Viral meningitis  varicella zoster virus': 4, 'Vitamin B12 deficiency': 10, 'Vitamin D deficiency': 10, 'Wernicke-Korsakoff complex:': 10, 'Yersinia enterocolitica infection': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programe\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (0,3,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Series' objects are mutable, thus they cannot be hashed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-70b45e01d4cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msymptom_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconditions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgroup_db\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATHOLOGY'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Index\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msymptom_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programe\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m         raise TypeError(\n\u001b[0m\u001b[0;32m   1786\u001b[0m             \u001b[1;34mf\"{repr(type(self).__name__)} objects are mutable, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m             \u001b[1;34mf\"thus they cannot be hashed\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed"
     ]
    }
   ],
   "source": [
    "output_path = \"./data_preprossing/rl/\"\n",
    "\n",
    "classlabel = [24, 29, 49, 38, 5, 3, 43, 48, 41, 37, 12, 31, 9, 42, 35, 28, 8, 14, 36, 4, 40, 19, 20, 21, 39, 53, 10, 25, 0, 44, 2, 17, 45]\n",
    "group_id = [1,2,3,4,5,6,7,8,9]\n",
    "symptom_columns = ['Index','GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "df = pd.read_csv(dataset_train,sep = \"\\t\")\n",
    "with open(symptom_map_file) as fp:\n",
    "        symptoms_db = json.load(fp)\n",
    "\n",
    "with open(condition_map_file) as fp:\n",
    "        conditions_db = json.load(fp)\n",
    "\n",
    "with open(group_file) as  fp:\n",
    "    group_db = json.load(fp)\n",
    "print(group_db)\n",
    "# groups = dict(map(reversed,group_db.items()))\n",
    "# print(groups)\n",
    "\n",
    "# def transform_symptoms_nlice_adv(symptom_str):  \n",
    "#     # print(symptom_str)\n",
    "#     symptom_list = symptom_str.split(\";\")\n",
    "#     transformed_symptoms = []\n",
    "#     for _symp_def in symptom_list:\n",
    "#         # print(_symp_def)\n",
    "#         sym_list = _symp_def.split(\":\")\n",
    "#         if(len(sym_list)==9):\n",
    "#             _symptom, _nature, _location, _intensity, _duration, _onset, _exciation, _frequency, _ = _symp_def.split(\":\")\n",
    "#             to_transform = [\n",
    "#                 \":\".join([str(_symptom)]),\n",
    "#                 \":\".join([str(_nature)]),\n",
    "#                 \":\".join([str(_location)]),\n",
    "#                 \":\".join([str(_intensity)]),\n",
    "#                 \":\".join([str(_duration)]),\n",
    "#                 \":\".join([str(_onset)]),\n",
    "#                 \":\".join([str(_exciation)]),\n",
    "#                 \":\".join([str(_frequency)])\n",
    "#                 ]\n",
    "#             transformed_str = \";\".join(to_transform)\n",
    "#             transformed_symptoms.append(transformed_str)\n",
    "\n",
    "#     return \";\".join(transformed_symptoms)\n",
    "for i in group_id:\n",
    "    # print(conditions_db)\n",
    "    conditions = dict(map(reversed, conditions_db.items()))\n",
    "    groups = dict(map(reversed,group_db.items()))\n",
    "    # print(groups)\n",
    "    symptom_columns = ['GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "    df = pd.read_csv(dataset_train,names=symptom_columns)\n",
    "    label = conditions.get(i)\n",
    "    df = df.loc[df['PATHOLOGY'] == i]\n",
    "    df.index.name = \"Index\"\n",
    "    df = df[symptom_columns]\n",
    "#     df = df.loc[df['NUM_SYMPTOMS']>=2]\n",
    "    df['NUM_SYMPTOMS'] = df.NUM_SYMPTOMS.apply(lambda n: int(n) if int(n) >=2 else np.NAN)\n",
    "    df['NUM_SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "    df['SYMPTOMS'] = df.SYMPTOMS.apply(lambda symptom: symptom if len(symptom.split(\";\")) >=2 else np.NAN)\n",
    "    df['SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['NUM_SYMPTOMS'],inplace=True)\n",
    "    df.dropna(subset=['SYMPTOMS'],inplace=True)\n",
    "    df = df.drop_duplicates()\n",
    "    if(len(df)>=2):\n",
    "        output_file = os.path.join(output_path, \"group\"+label,\"%s.csv\" % label)\n",
    "        df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./data_preprossing/rl/\"\n",
    "def extract_symptom_bygroup(filepath):\n",
    "    use_cols =['GENDER', 'RACE', 'AGE_BEGIN', 'PATHOLOGY', 'NUM_SYMPTOMS', 'SYMPTOMS'] \n",
    "    df = pd.read_csv(filepath)\n",
    "    # with open(symptom_db) as fp:\n",
    "    #     symptoms_mp = json.load(fp)\n",
    "    symptoms = df['SYMPTOMS']\n",
    "    condition = df['PATHOLOGY']\n",
    "    conditions_db = {}\n",
    "    count1= 0\n",
    "    for con in condition:\n",
    "        if con not in conditions_db:\n",
    "            conditions_db[con] = count1\n",
    "            count1+=1\n",
    "\n",
    "    symptoms_db = {}\n",
    "    count = 0\n",
    "    for sym in symptoms:\n",
    "        # print(sym)\n",
    "        symptom_list = sym.split(\";\")\n",
    "        for _symp_def in symptom_list:\n",
    "            sym_list = _symp_def.split(\":\")\n",
    "            _symptom, _nature, _location, _intensity, _duration, _onset, _exciation, _frequency, _ = _symp_def.split(\":\")\n",
    "            if(_symptom == \"Alterred_stool\"):\n",
    "                _symptom =\"Altered_stool\"\n",
    "            if(_symptom == \"Nausea_\"):\n",
    "                _symptom=\"Nausea\"\n",
    "            if(_symptom == \"Pain_relief_\"):\n",
    "                _symptom= \"Pain_relief\"\n",
    "            if(_symptom == \"Vomitting\"):\n",
    "                _symptom== \"Vomiting\"\n",
    "            if(_symptom == \"Incontinence_\"):\n",
    "                _symptom=\"Incontinence\"\n",
    "            \n",
    "            if _symptom not in symptoms_db:\n",
    "                symptoms_db[_symptom] = count\n",
    "                count+=1\n",
    "    return symptoms_db,conditions_db\n",
    "\n",
    "for id in [1,2,3,4,5]:\n",
    "    file = output_path+\"group\"+str(id)+\"/\"+str(id)+\".csv\"\n",
    "    all_symtom,all_condition = extract_symptom_bygroup(file)\n",
    "    all_symtom_file = output_path+\"group\"+str(id)+\"/\"+\"symptom\"+str(id)+\".json\"\n",
    "    with open(all_symtom_file, \"w\") as fp:\n",
    "        sorted_symptoms = sorted(all_symtom.keys())\n",
    "        symptom_map = {code: idx for idx, code in enumerate(sorted_symptoms)}\n",
    "        json.dump(all_symtom, fp, indent=4)\n",
    "\n",
    "    conditon_file = output_path+\"group\"+str(id)+\"/\"+\"condition\"+str(id)+\".json\"\n",
    "    with open(conditon_file, \"w\") as fp:\n",
    "        sorted_condition = sorted(all_condition.keys())\n",
    "        condition_map = {code: idx for idx, code in enumerate(sorted_condition)}\n",
    "        json.dump(all_condition, fp, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Acute pancreatitis': 2, 'Acute pyelonefritis': 7, 'Appendicitis': 2, 'Asthma': 1, 'Atrophic gastritis': 2, 'Bacterial meningitis': 4, 'Bladder cancer': 9, 'Breast cancer  female': 9, 'COPD': 1, 'Carpal tunnel syndrome': 5, 'Cauda equina': 5, 'Colon cancer': 9, 'Covid-19': 1, 'Female cystitis': 7, 'Functional constipation': 2, 'Genital herpes  female': 8, 'Genital herpes  male': 8, 'Giardiasis': 2, 'Gonorrhea, feminine': 8, 'Gout': 3, 'Hernia Nuclei Pulposi': 5, 'IBS (Constipation)': 2, 'Iron deficiency anaemia': 10, 'Lower urinary tract infection': 7, 'Lumbago': 5, 'Lumbar spinal stenosis': 5, 'Lung cancer': 9, 'Mastoiditis': 6, 'Migraine': 4, 'Norovirus gastroenteritis': 2, 'Oesophageal carcinoma': 9, 'Osteoarthritis': 3, 'Otitis externa': 6, 'Otitis media acuta': 6, 'Ovarian cancer': 9, 'Pneumococcal pneumonia': 1, 'Pneumothorax': 1, 'Pulmonary edema  old': 1, 'Pulmonary edema  oldest': 1, 'Pulmonary edema  young': 1, 'Rheumatoid arthritis  feminine': 3, 'Rheumatoid arthritis  masculine': 3, 'Salmonella infection': 2, 'Seasonal Influenza': 1, 'Subarachnoidal bleeding': 4, 'Tension type headache': 4, 'Testicular cancer': 9, 'Upper urinary tract infection': 7, 'Viral meningitis  enterovirus': 4, 'Viral meningitis  varicella zoster virus': 4, 'Vitamin B12 deficiency': 10, 'Vitamin D deficiency': 10, 'Wernicke-Korsakoff complex:': 10, 'Yersinia enterocolitica infection': 2}\n",
      "{2: ['Acute pancreatitis', 'Appendicitis', 'Atrophic gastritis', 'Functional constipation', 'Giardiasis', 'IBS (Constipation)', 'Norovirus gastroenteritis', 'Salmonella infection', 'Yersinia enterocolitica infection'], 7: ['Acute pyelonefritis', 'Female cystitis', 'Lower urinary tract infection', 'Upper urinary tract infection'], 1: ['Asthma', 'COPD', 'Covid-19', 'Pneumococcal pneumonia', 'Pneumothorax', 'Pulmonary edema  old', 'Pulmonary edema  oldest', 'Pulmonary edema  young', 'Seasonal Influenza'], 4: ['Bacterial meningitis', 'Migraine', 'Subarachnoidal bleeding', 'Tension type headache', 'Viral meningitis  enterovirus', 'Viral meningitis  varicella zoster virus'], 9: ['Bladder cancer', 'Breast cancer  female', 'Colon cancer', 'Lung cancer', 'Oesophageal carcinoma', 'Ovarian cancer', 'Testicular cancer'], 5: ['Carpal tunnel syndrome', 'Cauda equina', 'Hernia Nuclei Pulposi', 'Lumbago', 'Lumbar spinal stenosis'], 8: ['Genital herpes  female', 'Genital herpes  male', 'Gonorrhea, feminine'], 3: ['Gout', 'Osteoarthritis', 'Rheumatoid arthritis  feminine', 'Rheumatoid arthritis  masculine'], 10: ['Iron deficiency anaemia', 'Vitamin B12 deficiency', 'Vitamin D deficiency', 'Wernicke-Korsakoff complex:'], 6: ['Mastoiditis', 'Otitis externa', 'Otitis media acuta']}\n",
      "['Acute pancreatitis', 'Appendicitis', 'Atrophic gastritis', 'Functional constipation', 'Giardiasis', 'IBS (Constipation)', 'Norovirus gastroenteritis', 'Salmonella infection', 'Yersinia enterocolitica infection']\n",
      "['Acute pyelonefritis', 'Female cystitis', 'Lower urinary tract infection', 'Upper urinary tract infection']\n",
      "['Asthma', 'COPD', 'Covid-19', 'Pneumococcal pneumonia', 'Pneumothorax', 'Pulmonary edema  old', 'Pulmonary edema  oldest', 'Pulmonary edema  young', 'Seasonal Influenza']\n",
      "['Bacterial meningitis', 'Migraine', 'Subarachnoidal bleeding', 'Tension type headache', 'Viral meningitis  enterovirus', 'Viral meningitis  varicella zoster virus']\n",
      "['Bladder cancer', 'Breast cancer  female', 'Colon cancer', 'Lung cancer', 'Oesophageal carcinoma', 'Ovarian cancer', 'Testicular cancer']\n",
      "['Carpal tunnel syndrome', 'Cauda equina', 'Hernia Nuclei Pulposi', 'Lumbago', 'Lumbar spinal stenosis']\n",
      "['Genital herpes  female', 'Genital herpes  male', 'Gonorrhea, feminine']\n",
      "['Gout', 'Osteoarthritis', 'Rheumatoid arthritis  feminine', 'Rheumatoid arthritis  masculine']\n",
      "['Iron deficiency anaemia', 'Vitamin B12 deficiency', 'Vitamin D deficiency', 'Wernicke-Korsakoff complex:']\n",
      "['Mastoiditis', 'Otitis externa', 'Otitis media acuta']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "group_map = {}\n",
    "print(group_db)\n",
    "for k,v in group_db.items():\n",
    "    if v in group_map.keys():\n",
    "        group_map[v].append(k)\n",
    "    else:\n",
    "      group_map[v] = []\n",
    "      group_map[v].append(k)\n",
    "print(group_map)\n",
    "\n",
    "output_path = \"./data_preprossing/rl/\"\n",
    "for id, vs in group_map.items():\n",
    "    df = pd.read_csv(test,names=symptom_columns)\n",
    "    print(vs)\n",
    "    df = df.loc[df['PATHOLOGY'].isin(vs)]\n",
    "    symptom_columns = ['GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "    df.index.name = \"Index\"\n",
    "    df = df[symptom_columns]\n",
    "#     df = df.loc[df['NUM_SYMPTOMS']>=2]\n",
    "    # df['NUM_SYMPTOMS'] = df.NUM_SYMPTOMS.apply(lambda n: int(n) if int(n) >=2 else np.NAN)\n",
    "    df['NUM_SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "    df['SYMPTOMS'] = df.SYMPTOMS.apply(lambda symptom: symptom if len(symptom.split(\";\")) >=2 else np.NAN)\n",
    "    df['SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "    df.dropna(subset=['NUM_SYMPTOMS'],inplace=True)\n",
    "    df.dropna(subset=['SYMPTOMS'],inplace=True)\n",
    "    df = df.drop_duplicates()\n",
    "    if(len(df)>=2):\n",
    "\n",
    "        filegroup = output_path+\"group\"+str(id)\n",
    "        if not os.path.exists(filegroup):\n",
    "            os.makedirs(filegroup)\n",
    "        output_file = os.path.join(filegroup, \"%s.csv\" % id)\n",
    "        df.to_csv(output_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 9 fields in line 29525, saw 17\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ff79ba090d0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#         json.dump(all_condition, fp, indent=4)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mall_symtom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mall_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_symptom_bygroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[0mconditon_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"condition\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".json\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconditon_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ff79ba090d0b>\u001b[0m in \u001b[0;36mextract_symptom_bygroup\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_symptom_bygroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0muse_cols\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GENDER'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RACE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AGE_BEGIN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PATHOLOGY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'NUM_SYMPTOMS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SYMPTOMS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m# with open(symptom_db) as fp:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#     symptoms_mp = json.load(fp)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programe\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programe\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programe\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programe\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 9 fields in line 29525, saw 17\n"
     ]
    }
   ],
   "source": [
    "output_path = \"./data_v2/\"\n",
    "def extract_symptom_bygroup(filepath):\n",
    "    use_cols =['GENDER', 'RACE', 'AGE_BEGIN', 'PATHOLOGY', 'NUM_SYMPTOMS', 'SYMPTOMS'] \n",
    "    df = pd.read_csv(filepath)\n",
    "    # with open(symptom_db) as fp:\n",
    "    #     symptoms_mp = json.load(fp)\n",
    "    symptoms = df['SYMPTOMS']\n",
    "    condition = df['PATHOLOGY']\n",
    "    conditions_db = {}\n",
    "    count1= 0\n",
    "    for con in condition:\n",
    "        if con not in conditions_db:\n",
    "            conditions_db[con] = count1\n",
    "            count1+=1\n",
    "\n",
    "    symptoms_db = {}\n",
    "    count = 0\n",
    "    for sym in symptoms:\n",
    "        # print(sym)\n",
    "        symptom_list = sym.split(\";\")\n",
    "        for _symp_def in symptom_list:\n",
    "            sym_list = _symp_def.split(\":\")\n",
    "            _symptom, _nature, _location, _intensity, _duration, _onset, _exciation, _frequency, _ = _symp_def.split(\":\")\n",
    "            if(_symptom == \"Alterred_stool\"):\n",
    "                _symptom =\"Altered_stool\"\n",
    "            if(_symptom == \"Nausea_\"):\n",
    "                _symptom=\"Nausea\"\n",
    "            if(_symptom == \"Pain_relief_\"):\n",
    "                _symptom= \"Pain_relief\"\n",
    "            if(_symptom == \"Vomitting\"):\n",
    "                _symptom== \"Vomiting\"\n",
    "            if(_symptom == \"Incontinence_\"):\n",
    "                _symptom=\"Incontinence\"\n",
    "            if _symptom not in symptoms_db:\n",
    "                symptoms_db[_symptom] = count\n",
    "                count+=1\n",
    "    return symptoms_db,conditions_db\n",
    "\n",
    "# for id in [1,2,3,4,5]:\n",
    "#     file = output_path+\"group\"+str(id)+\"/\"+str(id)+\".csv\"\n",
    "#     all_symtom,all_condition = extract_symptom_bygroup(file)\n",
    "#     all_symtom_file = output_path+\"group\"+str(id)+\"/\"+\"symptom\"+str(id)+\".json\"\n",
    "#     with open(all_symtom_file, \"w\") as fp:\n",
    "#         sorted_symptoms = sorted(all_symtom.keys())\n",
    "#         symptom_map = {code: idx for idx, code in enumerate(sorted_symptoms)}\n",
    "#         json.dump(all_symtom, fp, indent=4)\n",
    "\n",
    "#     conditon_file = output_path+\"group\"+str(id)+\"/\"+\"condition\"+str(id)+\".json\"\n",
    "#     with open(conditon_file, \"w\") as fp:\n",
    "#         sorted_condition = sorted(all_condition.keys())\n",
    "#         condition_map = {code: idx for idx, code in enumerate(sorted_condition)}\n",
    "#         json.dump(all_condition, fp, indent=4) \n",
    "    \n",
    "all_symtom,all_condition = extract_symptom_bygroup(dataset_train)\n",
    "conditon_file = output_path+\"condition\"+\".json\"\n",
    "with open(conditon_file, \"w\") as fp:\n",
    "        sorted_condition = sorted(all_condition.keys())\n",
    "        condition_map = {code: idx for idx, code in enumerate(sorted_condition)}\n",
    "        json.dump(all_condition, fp, indent=4) \n",
    "symptom_file = output_path+\"symptom\"+\".json\"\n",
    "with open(symptom_file, \"w\") as fp:\n",
    "        sorted_symptoms = sorted(all_symtom.keys())\n",
    "        symptom_map = {code: idx for idx, code in enumerate(sorted_symptoms)}\n",
    "        json.dump(all_symtom, fp, indent=4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programe\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3165: DtypeWarning: Columns (0,3,5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GENDER   RACE  AGE_BEGIN                                 PATHOLOGY  \\\n",
      "Index                                                                        \n",
      "Index   GENDER   RACE  AGE_BEGIN                                 PATHOLOGY   \n",
      "0            F  white         51                                   Lumbago   \n",
      "1            F  white         16                 Norovirus gastroenteritis   \n",
      "2            M  white         71  Viral meningitis  varicella zoster virus   \n",
      "3            F  white          4                   Pulmonary edema  oldest   \n",
      "...        ...    ...        ...                                       ...   \n",
      "355216       M  white         69                                      Gout   \n",
      "355217       F  white         49                                      COPD   \n",
      "355218       M  white         80                                    Asthma   \n",
      "355219       M  white         88         Yersinia enterocolitica infection   \n",
      "355220       F  white         46            Rheumatoid arthritis  feminine   \n",
      "\n",
      "        NUM_SYMPTOMS                                           SYMPTOMS  \n",
      "Index                                                                    \n",
      "Index   NUM_SYMPTOMS                                           SYMPTOMS  \n",
      "0                  1       Pain_relief::::::Sitting/bending_forward::29  \n",
      "1                  4  Vomitting::::0_-_2_days::::29;Altered_stool:Mu...  \n",
      "2                  3  Vomiting::::::::46;Altered_stool:Diarrhea:::::...  \n",
      "3                  1                                     Pain::::::::42  \n",
      "...              ...                                                ...  \n",
      "355216             7  Difficulty_walking:::::::Periodic:42;Eruption:...  \n",
      "355217             3  Tightness::::::::33;Altered_breathing:Wheezing...  \n",
      "355218             3  Tightness::::::::33;Altered_breathing:Wheezing...  \n",
      "355219             3  Pain::::::::45;Vomiting::::::::28;Altered_stoo...  \n",
      "355220             5  Stiffness::::::Morning::49;Fever::::::::27;Dry...  \n",
      "\n",
      "[344780 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "output_path = \"./data_preprossing/output/data/\"\n",
    "data1k = \"./data_preprossing/output/data/total_1k.csv\"\n",
    "classlabel = [24, 29, 49, 38, 5, 3, 43, 48, 41, 37, 12, 31, 9, 42, 35, 28, 8, 14, 36, 4, 40, 19, 20, 21, 39, 53, 10, 25, 0, 44, 2, 17, 45]\n",
    "symptom_columns = ['Index','GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "symptom_columns = ['GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "df = pd.read_csv(dataset_train,names=symptom_columns)\n",
    "# df = pd.read_csv(data1k,names=symptom_columns)\n",
    "df.index.name = \"Index\"\n",
    "#     df = df.loc[df['NUM_SYMPTOMS']>=2]\n",
    "print(df)\n",
    "# df['NUM_SYMPTOMS'] = df.NUM_SYMPTOMS.apply(lambda n: int(n) if int(n) >=3 else np.NAN)\n",
    "# df['NUM_SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "df['SYMPTOMS'] = df.SYMPTOMS.apply(lambda symptom: symptom if len(symptom.split(\";\")) >=5 else np.NAN)\n",
    "df['SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['NUM_SYMPTOMS'],inplace=True)\n",
    "df.dropna(subset=['SYMPTOMS'],inplace=True)\n",
    "df = df.drop_duplicates()\n",
    "label = \"total_1k_min5\"\n",
    "output_file = os.path.join(output_path, \"%s.csv\" % label)\n",
    "df.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "path = \"./data_preprossing/output/datas\"\n",
    "output = \"./data_preprossing/output/data\"\n",
    "\n",
    "files = os.listdir(path)  #获取文件夹下所有文件名\n",
    "\n",
    "df1 = pd.read_csv(path + '/' + files[0],encoding='gbk')  #读取首个csv文件，保存到df1中\n",
    "df1 = df1.iloc[0:500]\n",
    "for file in files[1:]:     \n",
    "  df2 = pd.read_csv(path +'/' +  file,encoding='gbk')  #打开csv文件，注意编码问题，保存到df2中\n",
    "  df2 = df2.iloc[0:500] # first five rows of dataframe\n",
    "  df1 = pd.concat([df1,df2],axis=0,ignore_index=True)  #将df2数据与df1合并\n",
    "\n",
    "df1 = df1.drop_duplicates()   #去重\n",
    "# df1 = df1.reset_index(drop=True) #重新生成index\n",
    "df1.to_csv(output + '/' + 'total_500.csv') #将结果保存为新的csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "path = \"./data_preprossing/output/datas\"\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "def split_data(symptom_file, output_path, use_headers=False, train_split=0.8):\n",
    "    use_cols =['Delete','GENDER', 'RACE', 'AGE_BEGIN', 'PATHOLOGY', 'NUM_SYMPTOMS', 'SYMPTOMS'] \n",
    "\n",
    "    # pathlib.Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if use_headers:\n",
    "        df = pd.read_csv(symptom_file, names=use_cols)\n",
    "    else:\n",
    "        df = pd.read_csv(symptom_file)\n",
    "    df.index.name = \"Index\" \n",
    "    labels = df['PATHOLOGY']\n",
    "    df.drop('Delete',axis = 1,inplace = True)\n",
    "    df.to_csv(symptom_file)\n",
    "    # datas = df\n",
    "    # splitter = StratifiedShuffleSplit(1, train_size=train_split)\n",
    "    # train_index = None\n",
    "    # test_index = None\n",
    "    # for tr_idx, tst_index in splitter.split(datas, labels):\n",
    "    #     train_index = tr_idx\n",
    "    #     test_index = tst_index\n",
    "    #     break\n",
    "\n",
    "    # train_df = df.iloc[train_index]\n",
    "    # test_df = df.iloc[test_index]\n",
    "\n",
    "    # train_op = os.path.join(output_path, \"RL_train.csv\")\n",
    "    # test_op = os.path.join(output_path, \"RL_test.csv\")\n",
    "    # train_df.to_csv(train_op)\n",
    "    # test_df.to_csv(test_op)\n",
    " \n",
    "    # return train_op,test_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_data_dir = os.path.join(path, \"data\")\n",
    "# split into train and test\n",
    "split_data(\"./data_preprossing/output/data/total_100.csv\", op_data_dir,True,train_split=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_symptom_nlice(filepath):\n",
    "    use_cols =['GENDER', 'RACE', 'AGE_BEGIN', 'PATHOLOGY', 'NUM_SYMPTOMS', 'SYMPTOMS'] \n",
    "    df = pd.read_csv(filepath)\n",
    "    # with open(symptom_db) as fp:\n",
    "    #     symptoms_mp = json.load(fp)\n",
    "    symptoms = df['SYMPTOMS']\n",
    "    symptoms_db = {}\n",
    "#     excitation_encoding={\n",
    "#         \"other\":1\n",
    "#     }\n",
    "#     vas_encoding = {\"other\": 1}\n",
    "#     nature_encoding = {}\n",
    "#     frequency_encoding = {\n",
    "#     \"other\": 1}\n",
    "#     duration_encoding = {\n",
    "#     \"other\": 1}\n",
    "#     onset_encoding = {\n",
    "#     \"other\": 1\n",
    "# }\n",
    "#     location_encoding={\n",
    "#         \"other\":1\n",
    "#     }\n",
    "    nature=[]\n",
    "    location=[]\n",
    "    location_main=set([])\n",
    "    vas= []\n",
    "    excitation= []\n",
    "    frequency= []\n",
    "    onset=[]\n",
    "    duration=[]\n",
    "\n",
    "    count = 0\n",
    "    count_nlice = 2\n",
    "    for sym in symptoms:\n",
    "        # print(sym)\n",
    "        symptom_list = sym.split(\";\")\n",
    "        for _symp_def in symptom_list:\n",
    "            sym_list = _symp_def.split(\":\")\n",
    "            _symptom, _nature, _location, _intensity, _duration, _onset, _exciation, _frequency, _ = _symp_def.split(\":\")\n",
    "            if _symptom not in symptoms_db:\n",
    "                symptoms_db[_symptom] = count\n",
    "                count+=1\n",
    "            if _nature not in nature:\n",
    "                nature.append(_nature)          \n",
    "            if _location not in location:\n",
    "                location.append(_location)\n",
    "            if _frequency not in frequency:\n",
    "                frequency.append(_frequency)\n",
    "            if _exciation not in excitation:\n",
    "                excitation.append(_exciation)\n",
    "            if _intensity not in vas:\n",
    "                vas.append(_intensity)\n",
    "            if _onset not in onset:\n",
    "                onset.append(_onset)\n",
    "            if _duration not in duration:\n",
    "                duration.append(_duration)\n",
    "    return symptoms_db,nature,location,frequency,excitation,vas,onset,duration\n",
    "excitation_encoding={}\n",
    "vas_encoding = {}\n",
    "nature_encoding = {}\n",
    "frequency_encoding = {}\n",
    "duration_encoding = {}\n",
    "onset_encoding = {}\n",
    "location_encoding={} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_symtom,nature,location,frequency,excitation,vas,onset,duration = extract_symptom_nlice(test)\n",
    "data_dir = './data_preprossing/output/basic/min3/'\n",
    "all_symtom_file = \"./data_preprossing/output/basic/symptom_db_v1.json\"\n",
    "with open(all_symtom_file, \"w\") as fp:\n",
    "    sorted_symptoms = sorted(all_symtom.keys())\n",
    "    symptom_map = {code: idx for idx, code in enumerate(sorted_symptoms)}\n",
    "    json.dump(all_symtom, fp, indent=4)\n",
    "count = 1\n",
    "for item in nature:\n",
    "    nature_encoding[item] = count\n",
    "    count += 1\n",
    "nature_encoding_file = os.path.join(data_dir, \"nature_encoding.json\")\n",
    "with open(nature_encoding_file, \"w\") as fp:\n",
    "    json.dump(nature_encoding, fp, indent=4)\n",
    "\n",
    "count = 1\n",
    "for item in location:\n",
    "    location_encoding[item] = count\n",
    "    count += 1\n",
    "location_encoding_file = os.path.join(data_dir, \"body-parts-enc.json\")\n",
    "with open(location_encoding_file, \"w\") as fp:\n",
    "    json.dump(location_encoding, fp, indent=4)\n",
    "\n",
    "count = 1\n",
    "for item in frequency:\n",
    "    frequency_encoding[item] = count\n",
    "    count += 1\n",
    "frequency_encoding_file = os.path.join(data_dir, \"frequency_encoding.json\")\n",
    "with open(frequency_encoding_file, \"w\") as fp:\n",
    "    json.dump(frequency_encoding, fp, indent=4)\n",
    "\n",
    "count = 1\n",
    "for item in excitation:\n",
    "    excitation_encoding[item] = count\n",
    "    count += 1\n",
    "excitation_encoding_file = os.path.join(data_dir, \"excitation_encoding.json\")\n",
    "with open(excitation_encoding_file, \"w\") as fp:\n",
    "    json.dump(excitation_encoding, fp, indent=4)\n",
    "\n",
    "count = 1\n",
    "for item in vas:\n",
    "    vas_encoding[item] = count\n",
    "    count += 1\n",
    "vas_encoding_file = os.path.join(data_dir, \"vas_encoding.json\")\n",
    "with open(vas_encoding_file, \"w\") as fp:\n",
    "    json.dump(vas_encoding, fp, indent=4)\n",
    "\n",
    "count = 1\n",
    "for item in onset:\n",
    "    onset_encoding[item] = count\n",
    "    count += 1\n",
    "onset_encoding_file = os.path.join(data_dir, \"onset_encoding.json\")\n",
    "with open(onset_encoding_file, \"w\") as fp:\n",
    "    json.dump(onset_encoding, fp, indent=4)\n",
    "\n",
    "count = 1\n",
    "for item in duration:\n",
    "    duration_encoding[item] = count\n",
    "    count += 1\n",
    "duration_encoding_file = os.path.join(data_dir, \"duration_encoding.json\")\n",
    "with open(duration_encoding_file, \"w\") as fp:\n",
    "    json.dump(duration_encoding, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./data_preprossing/output/data/\"\n",
    "data1k = \"./data_preprossing/output/data/total_1k.csv\"\n",
    "classlabel = [24, 29, 49, 38, 5, 3, 43, 48, 41, 37, 12, 31, 9, 42, 35, 28, 8, 14, 36, 4, 40, 19, 20, 21, 39, 53, 10, 25, 0, 44, 2, 17, 45]\n",
    "symptom_columns = ['Index','GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "symptom_columns = ['GENDER','RACE','AGE_BEGIN','PATHOLOGY','NUM_SYMPTOMS','SYMPTOMS']\n",
    "df = pd.read_csv(dataset_train,names=symptom_columns)\n",
    "df.index.name = \"Index\"\n",
    "df['SYMPTOMS'] = df.SYMPTOMS.apply(lambda symptom: symptom if len(symptom.split(\";\")) >=3 else np.NAN)\n",
    "df['SYMPTOMS'].replace('', np.nan, inplace=True)\n",
    "df.dropna(subset=['NUM_SYMPTOMS'],inplace=True)\n",
    "df.dropna(subset=['SYMPTOMS'],inplace=True)\n",
    "df = df.drop_duplicates()\n",
    "label = \"total_1k_min3\"\n",
    "output_file = os.path.join(output_path, \"%s.csv\" % label)\n",
    "df.to_csv(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82027a20ddeb6a097671cda786a155c81104abc51a5a132134045c580b3bdcc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
